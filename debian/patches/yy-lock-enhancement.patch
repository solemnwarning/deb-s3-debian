Description: Lock safety enhancements
Origin: https://github.com/deb-s3/deb-s3/pull/5
Author: Yamashita, Yuu <peek824545201@gmail.com>

Index: deb-s3-debian/lib/deb/s3/cli.rb
===================================================================
--- deb-s3-debian.orig/lib/deb/s3/cli.rb
+++ deb-s3-debian/lib/deb/s3/cli.rb
@@ -163,12 +163,6 @@ class Deb::S3::CLI < Thor
     begin
       if options[:lock]
         log("Checking for existing lock file")
-        if Deb::S3::Lock.locked?(options[:codename], component, options[:arch], options[:cache_control])
-          lock = Deb::S3::Lock.current(options[:codename], component, options[:arch], options[:cache_control])
-          log("Repository is locked by another user: #{lock.user} at host #{lock.host}")
-          log("Attempting to obtain a lock")
-          Deb::S3::Lock.wait_for_lock(options[:codename], component, options[:arch], options[:cache_control])
-        end
         log("Locking repository for updates")
         Deb::S3::Lock.lock(options[:codename], component, options[:arch], options[:cache_control])
         @lock_acquired = true
@@ -351,6 +345,13 @@ class Deb::S3::CLI < Thor
     :aliases  => "-a",
     :desc     => "The architecture of the package in the APT repository."
 
+  option :lock,
+  :default  => false,
+  :type     => :boolean,
+  :aliases  => "-l",
+  :desc     => "Whether to check for an existing lock on the repository " +
+    "to prevent simultaneous updates "
+
   option :versions,
     :default  => nil,
     :type     => :array,
@@ -396,42 +397,56 @@ class Deb::S3::CLI < Thor
 
     configure_s3_client
 
-    # retrieve the existing manifests
-    log "Retrieving existing manifests"
-    from_manifest = Deb::S3::Manifest.retrieve(options[:codename],
-                                               component, arch,
+    begin
+      if options[:lock]
+        log("Checking for existing lock file")
+        log("Locking repository for updates")
+        Deb::S3::Lock.lock(options[:codename], to_component, options[:arch], options[:cache_control])
+        @lock_acquired = true
+      end
+
+      # retrieve the existing manifests
+      log "Retrieving existing manifests"
+      from_manifest = Deb::S3::Manifest.retrieve(options[:codename],
+                                                 component, arch,
+                                                 options[:cache_control],
+                                                 false, options[:skip_package_upload])
+      to_release = Deb::S3::Release.retrieve(to_codename)
+      to_manifest = Deb::S3::Manifest.retrieve(to_codename, to_component, arch,
                                                options[:cache_control],
-                                               false, options[:skip_package_upload])
-    to_release = Deb::S3::Release.retrieve(to_codename)
-    to_manifest = Deb::S3::Manifest.retrieve(to_codename, to_component, arch,
-                                             options[:cache_control],
-                                             options[:fail_if_exists],
-                                             options[:skip_package_upload])
-    packages = from_manifest.packages.select { |p|
-      p.name == package_name &&
-        (versions.nil? || versions.include?(p.full_version))
-    }
-    if packages.size == 0
-      error "No packages found in repository."
-    end
+                                               options[:fail_if_exists],
+                                               options[:skip_package_upload])
+      packages = from_manifest.packages.select { |p|
+        p.name == package_name &&
+          (versions.nil? || versions.include?(p.full_version))
+      }
+      if packages.size == 0
+        error "No packages found in repository."
+      end
+
+      packages.each do |package|
+        begin
+          to_manifest.add package, options[:preserve_versions], false
+        rescue Deb::S3::Utils::AlreadyExistsError => e
+          error("Preparing manifest failed because: #{e}")
+        end
+      end
 
-    packages.each do |package|
       begin
-        to_manifest.add package, options[:preserve_versions], false
+        to_manifest.write_to_s3 { |f| sublog("Transferring #{f}") }
       rescue Deb::S3::Utils::AlreadyExistsError => e
-        error("Preparing manifest failed because: #{e}")
+        error("Copying manifest failed because: #{e}")
       end
-    end
+      to_release.update_manifest(to_manifest)
+      to_release.write_to_s3 { |f| sublog("Transferring #{f}") }
 
-    begin
-      to_manifest.write_to_s3 { |f| sublog("Transferring #{f}") }
-    rescue Deb::S3::Utils::AlreadyExistsError => e
-      error("Copying manifest failed because: #{e}")
+      log "Copy complete."
+    ensure
+      if options[:lock] && @lock_acquired
+        Deb::S3::Lock.unlock(options[:codename], component, options[:arch], options[:cache_control])
+        log("Lock released.")
+      end
     end
-    to_release.update_manifest(to_manifest)
-    to_release.write_to_s3 { |f| sublog("Transferring #{f}") }
-
-    log "Copy complete."
   end
 
   desc "delete PACKAGE",
@@ -444,6 +459,13 @@ class Deb::S3::CLI < Thor
     :aliases  => "-a",
     :desc     => "The architecture of the package in the APT repository."
 
+  option :lock,
+  :default  => false,
+  :type     => :boolean,
+  :aliases  => "-l",
+  :desc     => "Whether to check for an existing lock on the repository " +
+    "to prevent simultaneous updates "
+
   option :versions,
     :default  => nil,
     :type     => :array,
@@ -470,49 +492,62 @@ class Deb::S3::CLI < Thor
 
     configure_s3_client
 
-    # retrieve the existing manifests
-    log("Retrieving existing manifests")
-    release  = Deb::S3::Release.retrieve(options[:codename], options[:origin], options[:suite])
-    if arch == 'all'
-      selected_arch = release.architectures
-    else
-      selected_arch = [arch]
-    end
-    all_found = 0
-    selected_arch.each { |ar|
-      manifest = Deb::S3::Manifest.retrieve(options[:codename], component, ar, options[:cache_control], false, options[:skip_package_upload])
-
-      deleted = manifest.delete_package(package, versions)
-      all_found += deleted.length
-      if deleted.length == 0
-          if versions.nil?
-              sublog("No packages were deleted. #{package} not found in arch #{ar}.")
-              next
-          else
-              sublog("No packages were deleted. #{package} versions #{versions.join(', ')} could not be found in arch #{ar}.")
-              next
-          end
+    begin
+      if options[:lock]
+        log("Checking for existing lock file")
+        log("Locking repository for updates")
+        Deb::S3::Lock.lock(options[:codename], component, options[:arch], options[:cache_control])
+        @lock_acquired = true
+      end
+
+      # retrieve the existing manifests
+      log("Retrieving existing manifests")
+      release  = Deb::S3::Release.retrieve(options[:codename], options[:origin], options[:suite])
+      if arch == 'all'
+        selected_arch = release.architectures
       else
-          deleted.each { |p|
-              sublog("Deleting #{p.name} version #{p.full_version} from arch #{ar}")
-          }
+        selected_arch = [arch]
       end
+      all_found = 0
+      selected_arch.each { |ar|
+        manifest = Deb::S3::Manifest.retrieve(options[:codename], component, ar, options[:cache_control], false, options[:skip_package_upload])
+
+        deleted = manifest.delete_package(package, versions)
+        all_found += deleted.length
+        if deleted.length == 0
+            if versions.nil?
+                sublog("No packages were deleted. #{package} not found in arch #{ar}.")
+                next
+            else
+                sublog("No packages were deleted. #{package} versions #{versions.join(', ')} could not be found in arch #{ar}.")
+                next
+            end
+        else
+            deleted.each { |p|
+                sublog("Deleting #{p.name} version #{p.full_version} from arch #{ar}")
+            }
+        end
 
-      log("Uploading new manifests to S3")
-      manifest.write_to_s3 {|f| sublog("Transferring #{f}") }
-      release.update_manifest(manifest)
-      release.write_to_s3 {|f| sublog("Transferring #{f}") }
+        log("Uploading new manifests to S3")
+        manifest.write_to_s3 {|f| sublog("Transferring #{f}") }
+        release.update_manifest(manifest)
+        release.write_to_s3 {|f| sublog("Transferring #{f}") }
 
-      log("Update complete.")
-    }
-    if all_found == 0
-      if versions.nil?
-        error("No packages were deleted. #{package} not found.")
-      else
-        error("No packages were deleted. #{package} versions #{versions.join(', ')} could not be found.")
+        log("Update complete.")
+      }
+      if all_found == 0
+        if versions.nil?
+          error("No packages were deleted. #{package} not found.")
+        else
+          error("No packages were deleted. #{package} versions #{versions.join(', ')} could not be found.")
+        end
+      end
+    ensure
+      if options[:lock] && @lock_acquired
+        Deb::S3::Lock.unlock(options[:codename], component, options[:arch], options[:cache_control])
+        log("Lock released.")
       end
     end
-
   end
 
 
Index: deb-s3-debian/lib/deb/s3/lock.rb
===================================================================
--- deb-s3-debian.orig/lib/deb/s3/lock.rb
+++ deb-s3-debian/lib/deb/s3/lock.rb
@@ -1,58 +1,122 @@
 # -*- encoding : utf-8 -*-
-require "tempfile"
-require "socket"
+require "base64"
+require "digest/md5"
 require "etc"
+require "socket"
+require "tempfile"
 
 class Deb::S3::Lock
-  attr_accessor :user
-  attr_accessor :host
+  attr_reader :user
+  attr_reader :host
 
-  def initialize
-    @user = nil
-    @host = nil
+  def initialize(user, host)
+    @user = user
+    @host = host
   end
 
   class << self
-    def locked?(codename, component = nil, architecture = nil, cache_control = nil)
-      Deb::S3::Utils.s3_exists?(lock_path(codename, component, architecture, cache_control))
-    end
-
-    def wait_for_lock(codename, component = nil, architecture = nil, cache_control = nil, max_attempts=60, wait=10)
-      attempts = 0
-      while self.locked?(codename, component, architecture, cache_control) do
-        attempts += 1
-        throw "Unable to obtain a lock after #{max_attempts}, giving up." if attempts > max_attempts
-        sleep(wait)
+    #
+    # 2-phase mutual lock mechanism based on `s3:CopyObject`.
+    #
+    # This logic isn't relying on S3's enhanced features like Object Lock
+    # because it imposes some limitation on using other features like
+    # S3 Cross-Region replication. This should work more than good enough 
+    # with S3's strong read-after-write consistency which we can presume
+    # in all region nowadays.
+    #
+    # This is relying on S3 to set object's ETag as object's MD5 if an
+    # object isn't comprized from multiple parts. We'd be able to presume
+    # it as the lock file is usually an object of some smaller bytes.
+    #
+    # acquire lock:
+    # 1. call `s3:HeadObject` on final lock object
+    #   1. If final lock object exists, restart from the beginning
+    #   2. Otherwise, call `s3:PutObject` to create initial lock object
+    # 2. Perform `s3:CopyObject` to copy from initial lock object
+    #    to final lock object with specifying ETag/MD5 of the initial
+    #    lock object
+    #   1. If copy object fails as `PreconditionFailed`, restart
+    #      from the beginning
+    #   2. Otherwise, lock has been acquired
+    #
+    # release lock:
+    # 1. remove final lock object by `s3:DeleteObject`
+    #
+    def lock(codename, component = nil, architecture = nil, cache_control = nil, max_attempts=60, max_wait_interval=10)
+      lockbody = "#{Etc.getlogin}@#{Socket.gethostname}"
+      initial_lockfile = initial_lock_path(codename, component, architecture, cache_control)
+      final_lockfile = lock_path(codename, component, architecture, cache_control)
+
+      md5_b64 = Base64.encode64(Digest::MD5.digest(lockbody))
+      md5_hex = Digest::MD5.hexdigest(lockbody)
+      max_attempts.times do |i|
+        wait_interval = [(1<<i)/10, max_wait_interval].min
+        if Deb::S3::Utils.s3_exists?(final_lockfile)
+          lock = current(codename, component, architecture, cache_control)
+          $stderr.puts("Repository is locked by another user: #{lock.user} at host #{lock.host} (phase-1)")
+          $stderr.puts("Attempting to obtain a lock after #{wait_interval} secound(s).")
+          sleep(wait_interval)
+        else
+          # upload the file
+          Deb::S3::Utils.s3.put_object(
+            bucket: Deb::S3::Utils.bucket,
+            key: Deb::S3::Utils.s3_path(initial_lockfile),
+            body: lockbody,
+            content_type: "text/plain",
+            content_md5: md5_b64,
+            metadata: {
+              "md5" => md5_hex,
+            },
+          )
+          begin
+            Deb::S3::Utils.s3.copy_object(
+              bucket: Deb::S3::Utils.bucket,
+              key: Deb::S3::Utils.s3_path(final_lockfile),
+              copy_source: "/#{Deb::S3::Utils.bucket}/#{Deb::S3::Utils.s3_path(initial_lockfile)}",
+              copy_source_if_match: md5_hex,
+            )
+            return
+          rescue Aws::S3::Errors::PreconditionFailed => error
+            lock = current(codename, component, architecture, cache_control)
+            $stderr.puts("Repository is locked by another user: #{lock.user} at host #{lock.host} (phase-2)")
+            $stderr.puts("Attempting to obtain a lock after #{wait_interval} second(s).")
+            sleep(wait_interval)
+          end
+        end
       end
-    end
-
-    def lock(codename, component = nil, architecture = nil, cache_control = nil)
-      lockfile = Tempfile.new("lockfile")
-      lockfile.write("#{Etc.getlogin}@#{Socket.gethostname}")
-      lockfile.close
-
-      Deb::S3::Utils.s3_store(lockfile.path,
-                              lock_path(codename, component, architecture, cache_control),
-                              "text/plain",
-                              cache_control)
+      # TODO: throw appropriate error class
+      raise("Unable to obtain a lock after #{max_attempts}, giving up.")
     end
 
     def unlock(codename, component = nil, architecture = nil, cache_control = nil)
+      Deb::S3::Utils.s3_remove(initial_lock_path(codename, component, architecture, cache_control))
       Deb::S3::Utils.s3_remove(lock_path(codename, component, architecture, cache_control))
     end
 
     def current(codename, component = nil, architecture = nil, cache_control = nil)
-      lock_content = Deb::S3::Utils.s3_read(lock_path(codename, component, architecture, cache_control))
-      lock_content = lock_content.split('@')
-      lock = Deb::S3::Lock.new
-      lock.user = lock_content[0]
-      lock.host = lock_content[1] if lock_content.size > 1
+      lockbody = Deb::S3::Utils.s3_read(lock_path(codename, component, architecture, cache_control))
+      if lockbody
+        user, host = lockbody.to_s.split("@", 2)
+        lock = Deb::S3::Lock.new(user, host)
+      else
+        lock = Deb::S3::Lock.new("unknown", "unknown")
+      end
       lock
     end
 
     private
+    def initial_lock_path(codename, component = nil, architecture = nil, cache_control = nil)
+      "dists/#{codename}/lockfile.lock"
+    end
+
     def lock_path(codename, component = nil, architecture = nil, cache_control = nil)
-      "dists/#{codename}/#{component}/binary-#{architecture}/lockfile"
+      #
+      # Acquire repository lock at `codename` level to avoid race between concurrent upload attempts.
+      #
+      # * `deb-s3 upload --arch=all` touchs multiples of `dists/{codename}/{component}/binary-*/Packages*`
+      # * All `deb-s3 upload` touchs `dists/{codename}/Release`
+      #
+      "dists/#{codename}/lockfile"
     end
   end
 end
Index: deb-s3-debian/spec/deb/s3/lock_spec.rb
===================================================================
--- deb-s3-debian.orig/spec/deb/s3/lock_spec.rb
+++ deb-s3-debian/spec/deb/s3/lock_spec.rb
@@ -4,34 +4,35 @@ require 'deb/s3/lock'
 require 'minitest/mock'
 
 describe Deb::S3::Lock do
-  describe :locked? do
-    it 'returns true if lock file exists' do
-      Deb::S3::Utils.stub :s3_exists?, true do
-        _(Deb::S3::Lock.locked?("stable")).must_equal true
-      end
-    end
-    it 'returns true if lock file exists' do
-      Deb::S3::Utils.stub :s3_exists?, false do
-        _(Deb::S3::Lock.locked?("stable")).must_equal false
-      end
-    end
-  end
+# describe :locked? do
+#   it 'returns true if lock file exists' do
+#     Deb::S3::Utils.stub :s3_exists?, true do
+#       _(Deb::S3::Lock.locked?("stable")).must_equal true
+#     end
+#   end
+#   it 'returns true if lock file exists' do
+#     Deb::S3::Utils.stub :s3_exists?, false do
+#       _(Deb::S3::Lock.locked?("stable")).must_equal false
+#     end
+#   end
+# end
 
-  describe :lock do
-    it 'creates a lock file' do
-      mock = MiniTest::Mock.new
-      mock.expect(:call, nil, 4.times.map {Object})
-      Deb::S3::Utils.stub :s3_store, mock do
-        Deb::S3::Lock.lock("stable")
-      end
-      mock.verify
-    end
-  end
+# describe :lock do
+#   it 'creates a lock file' do
+#     mock = MiniTest::Mock.new
+#     mock.expect(:call, nil, 4.times.map {Object})
+#     Deb::S3::Utils.stub :s3_store, mock do
+#       Deb::S3::Lock.lock("stable")
+#     end
+#     mock.verify
+#   end
+# end
 
   describe :unlock do
     it 'deletes the lock file' do
       mock = MiniTest::Mock.new
       mock.expect(:call, nil, [String])
+      mock.expect(:call, nil, [String])
       Deb::S3::Utils.stub :s3_remove, mock do
         Deb::S3::Lock.unlock("stable")
       end
